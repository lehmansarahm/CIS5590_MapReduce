=======================================================================

	Course:		CIS 5590, Spring 2017
	Professor:	X. He

	Author:		Sarah M. Lehman
	Email:		smlehman@temple.edu

	Program:	Semester Project, AWS Hadoop Map-Reduce

=======================================================================

BUILDING THE CODE BASE
-----------------------------
This code base can be bundled into a JAR file using the "build.xml" file at the project root.  If the developer is using Eclipse, the file may be right-clicked and run as an Ant build file.  If the developer wishes, the file may also be run using Ant from the command line.  The resulting JAR and MANIFEST files will be written to the "bin/jar" directory until the project root.
	
RUNNING THE PROGRAM
-----------------------------
The program requires an active installation of Java and Hadoop on the target machine in order to run.  The program may be run from the command line with the following instruction:
	> [Hadoop install dir] jar CIS5590_MapReduce_Lehman.jar [optional: [processing type] [input dir] [output dir]]

Example:
	> /usr/local/hadoop/bin/hadoop jar CIS5590_MapReduce_Lehman.jar (local file system)
	> /home/ubuntu/hadoop/bin/hadoop jar CIS5590_MapReduce_Lehman.jar (HDFS)

If no arguments are provided for processing type, input directory, or output directory, the following default values will be used:
	- processing type:  basic (searching for words "economy", "education", "government", "sports")
		- other options:  popular (searching for most popular words over five letters long for each country)
	- input directory:  ./input (folder of text files in current execution directory)
	- output directory:  ./output (will be overwritten if already exists)

NOTE THAT EXECUTION PARAMETERS MUST BE INCLUDED IN DESIGNATED ORDER.  All three arguments may be omitted, but if a given argument is included, all preceding arguments must also be included (i.e. processing type may be included without any other arguments, but output directory may not be included without also including processing type and input directory).
		
PROGRAM OUTPUT
-----------------------------
For each processing type, an output partition file will be written to the output directory of the user's choice.  It will contain the word selections and associated instance counts for each country, ranked in descending order of occurrence frequency.  For the user's convenience, this data will also be displayed in the console after a successful job completion.

If the user has indicated a "base" (or "target word") processing type, the program will also identify and output those countries which have the same order of word rankings.  (NOTE: this data is not written to a file, and will need to be saved manually by the user if a copy is to be kept.)

Regardless of processing type, the program will output the total execution time and contents of the generated output files to the terminal for user review.  The final output may be written to its own file rather than the terminal if the user chooses.

** Examples of program output may be found in the "references" directory under the project root **

VERIFIED ENVIRONMENTS
-----------------------------
This program was verified on a system with the following specifications:
	- Ubuntu v. 16.04 operating system
	- Java v. 1.8.0_121
	- Hadoop v. 2.8.0

This program was tested locally using a virtual machine with the following specifications:
	- VirtualBox v. 5.1.14 with allocations:
		- 4GB RAM
		- 2 CPU cores
	- 2015 Macbook Pro, running OSX 12 (Sierra) with:
		- 8GB RAM
		- 2.7 GHz Intel i5 CPU

This program was tested remotely using AWS EC2 instances with the following specifications:
	- Instance type:  T2 micro
	- Base AMI:  Ubuntu v. 16.04
	- Root device type:  EBS (default)
	
AMI's
-----------------------------
Public AMI's may be found on the AWS EC2 dashboard by searching for "HD-AMI-Lehman" among the community images.  The following four images are currently available:
	- NameNode
	- SNN (SecondaryNameNode)
	- DataNode
	- Standalone